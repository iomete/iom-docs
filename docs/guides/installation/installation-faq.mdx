---
title: Installation FAQ
last_update:
  date: 10/04/2022
---
import Question from "@site/src/components/Question";

<Question title="Using AWS Profiles">A <b>named profile</b> is a collection of settings and credentials that you can apply to an AWS CLI command. When you specify a profile to run a command, the settings and credentials are used to run that command. Multiple <b>named profiles</b> can be stored in the <code>config</code> and <code>credentials</code> files.

For detailed information see:  [Named profiles for the AWS CLI](https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-profiles.html)

### Using profile:

After successfully creating Profile (ex. iomete-stage) need to export the profile to the environment before running terraform. ex:

```bash
export AWS_PROFILE=iomete-stage

## Then run terraform code as below

terraform init
terraform plan
terraform apply
```

P.S. Using the profile in terraform code will create additional works (ex. need to declare profile name in all providers).

We recommend exporting the profile to the environment before running the code. 

If using only one account (only default profile) no need to export or separate the AWS profile.

Just run the Terraform code.
</Question>

<Question title="Saving terraform state">To move or save Terraform state files to an Amazon S3 bucket, follow these steps:

1. Create an S3 bucket in your AWS account in any region.
2. Add the Terraform code to a configuration file, such as **`main.tf`**.

```bash

terraform {
  backend "s3" {
    bucket         = "your-bucket-name"
    region         = "aws-region"
    key            = "terraform.tfstate"
  }
}
```

3. Run Terraform 

```bash
terraform init
terraform plan
terraform apply
```

If the output that you receive is similar to the example displayed below, then you can be assured that your code has been executed successfully.

:::info

"Successfully configured the backend "s3"! Terraform will automatically
use this backend unless the backend configuration changes."

:::

```bash
terraform init

Successfully configured the backend "s3"! Terraform will automatically
use this backend unless the backend configuration changes.

Initializing provider plugins...
- Reusing previous version of hashicorp/kubernetes from the dependency lock file
- Reusing previous version of hashicorp/tls from the dependency lock file
- Reusing previous version of hashicorp/aws from the dependency lock file
- Reusing previous version of hashicorp/null from the dependency lock file
- Reusing previous version of hashicorp/helm from the dependency lock file
- Reusing previous version of gavinbunney/kubectl from the dependency lock file
- Reusing previous version of hashicorp/cloudinit from the dependency lock file
- Reusing previous version of hashicorp/local from the dependency lock file
- Reusing previous version of hashicorp/random from the dependency lock file
- Using previously-installed hashicorp/local v2.1.0
- Using previously-installed hashicorp/kubernetes v2.17.0
- Using previously-installed hashicorp/aws v4.53.0
- Using previously-installed hashicorp/helm v2.8.0
- Using previously-installed hashicorp/cloudinit v2.2.0
- Using previously-installed hashicorp/random v3.1.0
- Using previously-installed hashicorp/tls v4.0.4
- Using previously-installed hashicorp/null v3.1.0
- Using previously-installed gavinbunney/kubectl v1.14.0

Terraform has been successfully initialized!

You may now begin working with Terraform. Try running "terraform plan" to see
any changes that are required for your infrastructure. All Terraform commands
should now work.

If you ever set or change modules or backend configuration for Terraform,
rerun this command to reinitialize your working directory. If you forget, other
commands will detect it and remind you to do so if necessary.
```

To verify that the **`.tfstate`** file has been saved to your bucket, you can check the contents of the bucket to confirm that the file exists. If the file is present, it means that the state file has been successfully saved.
</Question>

<Question title="Define additional administrators">AWS Key Management Service (KMS) is an Amazon Web Services product that allows administrators to create, delete and control keys that encrypt data stored in AWS databases and products.

AWS KMS can be accessed within [AWS Identity and Access Management](https://www.techtarget.com/searchaws/definition/Amazon-Web-Services-AWS-Identity-and-Access-Management-IAM) by selecting the "Encryption Keys" section or by using the AWS KMS command-line interface or software development kit

IOMETE customer-stack Terraform module will use or create a KMS key only who run the Terraform code if additional administrator ARN`s not added. (AWS KMS see:[https://docs.aws.amazon.com/kms/latest/developerguide/overview.html](https://docs.aws.amazon.com/kms/latest/developerguide/overview.html) )

Adding an additional administrator to the system will grant them access to manage Kubernetes resources in EKS. By default, only the creator of the resources has access to Kubernetes. To add additional administrators, include their user Amazon Resource Names (ARNs) when running the Terraform code. It is important to note that when adding additional ARNs, the creators must include their own ARNs in the list to ensure that they retain access to the resources.

:::tip
 Example: additional_administrators = ["arn:aws:iam::1234567890:user/your_arn", "arn:aws:iam::1234567890:user/user2", "arn:aws:iam::1234567890:user/user3"]
:::
</Question>

<Question title="Public Access Restriction">Using static IP for restricting access 

IOMETE control plane uses EKS (AWS Kubernetes service) API address to connect and control data lakehouse and spark jobs. Downloading or copying code from IOMETE control-plane **kubernetes_public_access_cidrs** commented by default. 

If the customer has security compliance or any other concern to needs to restrict public access to EKS API must follow the next steps:

1. Uncomment  **kubernetes_public_access_cidrs** in Terraform script
2. Add static IP address (or address range for ex.: 5.194.94.20/30) to **"your_ip_range/mask"** section.

:::caution

Please do not remove IOMETE's IP addresses (18.156.67.183/32", "54.235.211.34"/32). Removing them will prevent the control plane from accessing the cluster, and the lakehouse will be inoperable.

:::

:::caution

Need Static IP address or address range to restrict EKS public access.

::: 

:::caution

Please consider that only deployed IP addresses will access all resources and EKS created by Terraform.

:::  
</Question>