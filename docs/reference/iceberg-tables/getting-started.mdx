---
title: Getting started with Apache Iceberg
sidebar_label: Getting Started
description: Starting Apache Spark as a compute engine, with Apache Iceberg provider with additional optimization and packaging
last_update:
  date: 09/30/2022
  author: Vugar Dadalov
---

**IOMETE** uses [Apache Spark](https://spark.apache.org/) as a compute engine, with [Apache Iceberg](https://iceberg.apache.org/) provider with additional optimization and packaging.

This guide covers the essentials of working with Apache Iceberg tables in IOMETE. For a broader overview, see [What is IOMETE?](/docs/getting-started/what-is-iomete) and [Architecture](/docs/getting-started/architecture).

---

## Apache Iceberg

Apache Iceberg is an open table format for huge analytic datasets. It provides a rich feature set:

- ACID transactions and insert/merge/delete
- [Schema evolution](https://iceberg.apache.org/evolution#schema-evolution) supports add, drop, update, or rename, and has [no side-effects](https://iceberg.apache.org/evolution#correctness)
- [Hidden partitioning](https://iceberg.apache.org/partitioning) prevents user mistakes that cause silently incorrect results or extremely slow queries
- [Partition layout evolution](https://iceberg.apache.org/evolution#partition-evolution) can update the layout of a table as data volume or query patterns change
- [Time travel](https://iceberg.apache.org/spark-queries#time-travelr) enables reproducible queries that use exactly the same table snapshot, or lets users easily examine changes
- Version rollback allows users to quickly correct problems by resetting tables to a good state

:::info
Iceberg is the default provider. That means the followings have the same effect:

- `create table test1(id string);`
- `create table test1(id string) using icerberg;`
  :::

<br />

### Creating a table

```sql
CREATE TABLE table1 (id bigint, data string);
```

Iceberg supports the full range of SQL DDL commands, including:

- [CREATE TABLE ... PARTITIONED BY](https://iceberg.apache.org/spark-ddl/#create-table)
- [CREATE TABLE ... AS SELECT](https://iceberg.apache.org/spark-ddl/#create-table-as-select)
- [ALTER TABLE](https://iceberg.apache.org/spark-ddl/#alter-table)
- [DROP TABLE](https://iceberg.apache.org/spark-ddl/#drop-table)

For comprehensive DDL syntax and examples, see our [Iceberg DDL Guide](./ddl).

<br />

### Writing

Once your table is created, insert data using [INSERT INTO:](https://iceberg.apache.org/spark-writes/#insert-into)

```sql
INSERT INTO table1 VALUES (1, 'a'), (2, 'b'), (3, 'c');
INSERT INTO table1 SELECT id, data FROM source WHERE length(data) = 1;
```

Row-level SQL updates using [MERGE INTO](https://iceberg.apache.org/spark-writes/#merge-into) and [DELETE FROM](https://iceberg.apache.org/docs/latest/spark-writes/):

```sql
MERGE INTO local.db.target t USING (SELECT * FROM updates) u ON t.id = u.id
WHEN MATCHED THEN UPDATE SET t.count = t.count + u.count
WHEN NOT MATCHED THEN INSERT *
```

For detailed write operation examples, see our [Iceberg Writes Guide](./writes).

<br />

### Reading

```sql
SELECT count(1) as count, data
FROM table1
GROUP BY data
```

To view all of the snapshots in a table, use the `snapshots` metadata table:

```sql
SELECT * FROM default.table1.snapshots
```

| committed_at            | snapshot_id    | parent_id | operation | manifest_list                                      |
| ----------------------- | -------------- | --------- | --------- | -------------------------------------------------- |
| 2019-02-08 03:29:51.215 | 57897183625154 | null      | append    | s3://.../table/metadata/snap-57897183625154-1.avro |
| ...                     | ...            | ...       | ...       | ...                                                |

For more query examples and metadata tables, see our [Iceberg Queries Guide](./queries).

## Learn More

### Core Iceberg Documentation
- **[Iceberg DDL Operations](./ddl)** - Complete guide to DDL commands
- **[Iceberg Write Operations](./writes)** - INSERT, UPDATE, DELETE, MERGE operations
- **[Iceberg Query Operations](./queries)** - SELECT queries and metadata tables
- **[Iceberg Time Travel](./time-travel)** - Query historical data and snapshots
- **[Iceberg Maintenance](./maintenance)** - Optimize and maintain your tables
- **[Iceberg Procedures](./iceberg-procedures)** - System procedures for table management

### Related Resources
- **[SQL Quick Start](/docs/reference/sql-quick-start/sql-ddl-examples)** - Quick reference for common operations
- **[Virtual Lakehouses](/docs/user-guide/virtual-lakehouses)** - Create and manage compute clusters
- **[Spark Jobs](/docs/user-guide/spark-jobs)** - Run batch processing jobs
- **[Data Compaction Job](/docs/open-source-spark-jobs/data-compaction-job)** - Automate table optimization

### Practical Guides
- **Tutorial**: [Iceberg Compaction (CoW vs MoR)](/docs/tutorials/compaction-cow-mor)
- **Blog**: [Iceberg Maintenance Runbook](/blog/iceberg-maintenance-runbook)
- **Blog**: [Iceberg Deep Dive](/blog/iceberg-deep-dive)
- **Blog**: [Why Apache Iceberg Wins](/blog/why-apache-iceberg-win)
- **Blog**: [Iceberg Disaster Recovery](/blog/iceberg-disaster-recovery)
